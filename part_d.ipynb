{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0mw1C2z_Cja"
   },
   "source": [
    "Mask Segmentation Using U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6c51q0ntGJv",
    "outputId": "2ca019df-2e47-4804-b207-2cb54c67993b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1is36NDJ3zwL",
    "outputId": "b2db3b5c-946d-4a7a-b160-188e5f051e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-Net Model Initialized Successfully on CPU\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        def conv_block(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_c),  # BatchNorm speeds up training\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.LeakyReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        self.encoder1 = conv_block(in_channels, 16)  # Reduced from 64 to 16\n",
    "        self.encoder2 = conv_block(16, 32)           # Reduced from 128 to 32\n",
    "        self.encoder3 = conv_block(32, 64)           # Reduced from 256 to 64\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = conv_block(64, 128)        # Reduced from 512 to 128\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder3 = conv_block(128, 64)\n",
    "        self.upconv2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.decoder2 = conv_block(64, 32)\n",
    "        self.upconv1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n",
    "        self.decoder1 = conv_block(32, 16)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(16, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(self.pool(e1))\n",
    "        e3 = self.encoder3(self.pool(e2))\n",
    "\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "\n",
    "        d3 = self.decoder3(torch.cat([self.upconv3(b), e3], dim=1))\n",
    "        d2 = self.decoder2(torch.cat([self.upconv2(d3), e2], dim=1))\n",
    "        d1 = self.decoder1(torch.cat([self.upconv1(d2), e1], dim=1))\n",
    "\n",
    "        return torch.sigmoid(self.final_conv(d1))\n",
    "\n",
    "# Initialize model on CPU\n",
    "model = UNet().to(device)\n",
    "print(\"U-Net Model Initialized Successfully on CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VNGinFw64bPz",
    "outputId": "93ba211c-c47b-4cee-8e6f-1daec790ea36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded: 9382 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import multiprocessing\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Dataset Class\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.image_files[idx])\n",
    "\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Resize to 32x32 for faster training\n",
    "        image = cv2.resize(image, (32, 32)) / 255.0\n",
    "        mask = cv2.resize(mask, (32, 32)) / 255.0\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)\n",
    "        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Get available CPU cores\n",
    "num_workers = min(2, multiprocessing.cpu_count())  # Avoid system overload\n",
    "\n",
    "# Load dataset\n",
    "image_dir = \"image/MSFD/1/face_crop\"\n",
    "mask_dir = \"image/MSFD/1/face_crop_segmentation\"\n",
    "dataset = SegmentationDataset(image_dir, mask_dir)\n",
    "\n",
    "# Optimized DataLoader for CPU\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True,\n",
    "    num_workers=num_workers, pin_memory=False  # No pin_memory for CPU\n",
    ")\n",
    "\n",
    "print(f\"Dataset Loaded: {len(dataset)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Co54-t4Q4tg6",
    "outputId": "00360133-c58c-4203-f4e1-89360ad184a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1621\n",
      "Epoch [2/5], Loss: 0.1425\n",
      "Epoch [3/5], Loss: 0.1355\n",
      "Epoch [4/5], Loss: 0.1294\n",
      "Epoch [5/5], Loss: 0.1266\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_unet(model, dataloader, criterion, optimizer, device, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for images, masks in dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            loss.backward()  # Compute gradients\n",
    "            optimizer.step()  # Update model weights\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# Initialize Loss and Optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Train the model on CPU\n",
    "train_unet(model, dataloader, criterion, optimizer, device=\"cpu\", epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNzBfyc44v9w",
    "outputId": "afdda179-3c3f-4767-b19a-9c7ce829447d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average IoU: 0.8589\n",
      "Average Dice Score: 0.9218\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    iou_values = []\n",
    "    dice_values = []\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            pred_masks = (outputs > 0.5).float()\n",
    "\n",
    "            intersection = (pred_masks * masks).sum()\n",
    "            union = (pred_masks + masks).sum() - intersection\n",
    "            dice = (2. * intersection) / (pred_masks.sum() + masks.sum())\n",
    "\n",
    "            if union > 0:\n",
    "                iou = intersection / union\n",
    "                iou_values.append(iou.item())\n",
    "            dice_values.append(dice.item())\n",
    "\n",
    "    print(f\"Average IoU: {np.mean(iou_values):.4f}\")\n",
    "    print(f\"Average Dice Score: {np.mean(dice_values):.4f}\")\n",
    "\n",
    "# Evaluate Model\n",
    "evaluate(model, dataloader, device)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
